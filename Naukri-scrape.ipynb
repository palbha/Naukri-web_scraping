{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3> Web Scraping Naukri.com for Data Science related jobs <h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using selenium ,you need to download web driver for your browser from :https://sites.google.com/a/chromium.org/chromedriver/downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "driver = webdriver.Chrome(\"C:/Users/palbh/Documents/Python/self learning/selenium/web_driver/chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/data-scientist-jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are planning to save in particular some basic details for a job \n",
    "so Lets intialize a dataframe in which we will store all the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns = ['Title','company','key_skill','experience','location']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = driver.find_elements_by_xpath(\"/html/body/div[5]/div/div[2]/div//div[@type='tuple']\")\n",
    "\n",
    "#Lets store all the job_ids in a list and then fetch all the details of a job corresponding to a particular job id\n",
    "job_ids = []\n",
    "for i in ids:\n",
    "    job_ids.append(i.get_attribute('id'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in job_ids:\n",
    "    #Extracting Title from for each job id\n",
    "    title_elem = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/span[@class=\"content\"]/ul/li')[0]\n",
    "    j_title = title_elem.get_attribute('title')\n",
    "\n",
    "   #Extracting Company name from for each job id\n",
    "    comp_element = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/span[@class=\"content\"]/span[@class=\"orgRating\"]/span')[0]\n",
    "    j_comp = comp_element.text\n",
    "\n",
    "    #Extracting Experience for each job id\n",
    "    exp_elem = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/span[@class=\"content\"]/span[@class=\"exp\"]')[0]\n",
    "    j_exp = exp_elem.text\n",
    "    \n",
    "    #Extracting Key skills for each job id\n",
    "    ks_elem = driver.find_elements_by_xpath('//*[@id=\"250319902972\"]/span/div[2]/span[@class=\"skill\"]')[0]\n",
    "    j_ks = ks_elem.text\n",
    "    \n",
    "     #Extracting Location for each job id\n",
    "    loc_elem = driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/span[@class=\"content\"]/span[@class=\"loc\"]')[0]\n",
    "    j_loc = loc_elem.text\n",
    "    \n",
    "    #Appending all the extracted details\n",
    "    df.loc[len(df)] = [j_title,j_comp,j_ks,j_exp,j_loc]\n",
    "    \n",
    "                                   \n",
    "   #Adding date, userid and comment for each user in a dataframe    \n",
    "    #df.loc[len(df)] = [date,userid,comment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now our data is stored in a dataframe  . \n",
    "We can also store the dataframe as an excel file in our system for further usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"output.xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
